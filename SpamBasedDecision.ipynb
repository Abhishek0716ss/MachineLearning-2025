{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUYwRY61YG5kmWMvuAjbhU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishek0716ss/MachineLearning-2025/blob/main/SpamBasedDecision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAFlaGWQj5Mm",
        "outputId": "35bba942-85ec-4445-e9d1-bd567c03990b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Dataset loaded successfully!\n",
            "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
            "0            0.00               0.64           0.64           0.0   \n",
            "1            0.21               0.28           0.50           0.0   \n",
            "2            0.06               0.00           0.71           0.0   \n",
            "3            0.00               0.00           0.00           0.0   \n",
            "4            0.00               0.00           0.00           0.0   \n",
            "\n",
            "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
            "0           0.32            0.00              0.00                0.00   \n",
            "1           0.14            0.28              0.21                0.07   \n",
            "2           1.23            0.19              0.19                0.12   \n",
            "3           0.63            0.00              0.31                0.63   \n",
            "4           0.63            0.00              0.31                0.63   \n",
            "\n",
            "   word_freq_order  word_freq_mail  ...  char_freq_semicolon  \\\n",
            "0             0.00            0.00  ...                 0.00   \n",
            "1             0.00            0.94  ...                 0.00   \n",
            "2             0.64            0.25  ...                 0.01   \n",
            "3             0.31            0.63  ...                 0.00   \n",
            "4             0.31            0.63  ...                 0.00   \n",
            "\n",
            "   char_freq_parenthesis  char_freq_bracket  char_freq_exclamation  \\\n",
            "0                  0.000                0.0                  0.778   \n",
            "1                  0.132                0.0                  0.372   \n",
            "2                  0.143                0.0                  0.276   \n",
            "3                  0.137                0.0                  0.137   \n",
            "4                  0.135                0.0                  0.135   \n",
            "\n",
            "   char_freq_dollar  char_freq_hash  capital_run_length_average  \\\n",
            "0             0.000           0.000                       3.756   \n",
            "1             0.180           0.048                       5.114   \n",
            "2             0.184           0.010                       9.821   \n",
            "3             0.000           0.000                       3.537   \n",
            "4             0.000           0.000                       3.537   \n",
            "\n",
            "   capital_run_length_longest  capital_run_length_total  spam  \n",
            "0                          61                       278     1  \n",
            "1                         101                      1028     1  \n",
            "2                         485                      2259     1  \n",
            "3                          40                       191     1  \n",
            "4                          40                       191     1  \n",
            "\n",
            "[5 rows x 58 columns]\n",
            "Training set shape: (3680, 57) (3680,)\n",
            "Testing set shape: (921, 57) (921,)\n",
            " Model training complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4056972124.py:77: RuntimeWarning: divide by zero encountered in log\n",
            "  log_posterior += np.log(likelihood)\n",
            "/tmp/ipython-input-4056972124.py:80: RuntimeWarning: invalid value encountered in scalar subtract\n",
            "  exp_posteriors = {c: np.exp(lp - max_log_posterior) for c, lp in posteriors.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Accuracy: 0.8339\n",
            "\n",
            "Confusion Matrix:\n",
            "[[420 138]\n",
            " [ 15 348]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.75      0.85       558\n",
            "           1       0.72      0.96      0.82       363\n",
            "\n",
            "    accuracy                           0.83       921\n",
            "   macro avg       0.84      0.86      0.83       921\n",
            "weighted avg       0.87      0.83      0.84       921\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import urllib.request\n",
        "\n",
        "# --- Step 1: Download the dataset automatically ---\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
        "urllib.request.urlretrieve(url, \"spambase.data\")\n",
        "\n",
        "# --- Step 2: Define column names ---\n",
        "column_names = [\n",
        "    'word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n",
        "    'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet',\n",
        "    'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will',\n",
        "    'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free',\n",
        "    'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit',\n",
        "    'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money',\n",
        "    'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650',\n",
        "    'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857',\n",
        "    'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology',\n",
        "    'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct',\n",
        "    'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project',\n",
        "    'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n",
        "    'char_freq_semicolon', 'char_freq_parenthesis', 'char_freq_bracket', 'char_freq_exclamation',\n",
        "    'char_freq_dollar', 'char_freq_hash', 'capital_run_length_average',\n",
        "    'capital_run_length_longest', 'capital_run_length_total', 'spam'\n",
        "]\n",
        "\n",
        "# --- Step 3: Load the dataset ---\n",
        "df = pd.read_csv(\"spambase.data\", header=None, names=column_names)\n",
        "print(\" Dataset loaded successfully!\")\n",
        "print(df.head())\n",
        "\n",
        "# --- Step 4: Split into features and labels ---\n",
        "X = df.drop('spam', axis=1)\n",
        "y = df['spam']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
        "\n",
        "# --- Step 5: Define Bayesian Classifier ---\n",
        "class BayesianClassifier:\n",
        "    def __init__(self):\n",
        "        self.priors = {}\n",
        "        self.feature_params = {}\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        classes = y_train.unique()\n",
        "        for c in classes:\n",
        "            self.priors[c] = np.mean(y_train == c)\n",
        "            X_c = X_train[y_train == c]\n",
        "            self.feature_params[c] = {\n",
        "                col: {'mean': np.mean(X_c[col]), 'std': np.std(X_c[col])}\n",
        "                for col in X_train.columns\n",
        "            }\n",
        "\n",
        "    def calculate_likelihood(self, x, feature_name, class_label):\n",
        "        params = self.feature_params[class_label][feature_name]\n",
        "        mean = params['mean']\n",
        "        std = params['std']\n",
        "        if std == 0:\n",
        "            return 1e-9\n",
        "        return norm.pdf(x, mean, std)\n",
        "\n",
        "    def calculate_posterior(self, x_row):\n",
        "        posteriors = {}\n",
        "        for c, prior in self.priors.items():\n",
        "            log_posterior = np.log(prior)\n",
        "            for feature_name, value in x_row.items():\n",
        "                likelihood = self.calculate_likelihood(value, feature_name, c)\n",
        "                log_posterior += np.log(likelihood)\n",
        "            posteriors[c] = log_posterior\n",
        "        max_log_posterior = max(posteriors.values())\n",
        "        exp_posteriors = {c: np.exp(lp - max_log_posterior) for c, lp in posteriors.items()}\n",
        "        sum_exp_posteriors = sum(exp_posteriors.values())\n",
        "        return {c: exp_posteriors[c] / sum_exp_posteriors for c in exp_posteriors}\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = []\n",
        "        for _, row in X_test.iterrows():\n",
        "            posteriors = self.calculate_posterior(row)\n",
        "            predicted_class = max(posteriors, key=posteriors.get)\n",
        "            predictions.append(predicted_class)\n",
        "        return np.array(predictions)\n",
        "\n",
        "# --- Step 6: Train and evaluate the model ---\n",
        "bayesian_model = BayesianClassifier()\n",
        "bayesian_model.fit(X_train, y_train)\n",
        "print(\" Model training complete.\")\n",
        "\n",
        "y_pred = bayesian_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XH2fbw4_mjuT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}